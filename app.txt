from rag.loader import load_pdfs
from rag.chunker import split_documents
from rag.embeddings import get_embedding_model
from rag.vectorstore import create_vectorstore
from rag.retriever import create_retriever
from rag.chain import create_llm, generate_answer

def main():
    print("Loading PDFs...")
    documents = load_pdfs()
    print(f"Loaded {len(documents)} pages.")

    print("Splitting text...")
    chunks = split_documents(documents)
    print(f"Created {len(chunks)} chunks.")

    print("Creating embeddings...")
    embedding_model = get_embedding_model()

    print("Creating vector store...")
    vectorstore = create_vectorstore(chunks, embedding_model)

    print("Creating retriever...")
    retriever = create_retriever(vectorstore)

    print("Loading LLM...")
    llm = create_llm()

    print("\nSystem ready! Ask questions (type 'exit' to quit)")

    while True:
        query = input("\nQuestion: ")

        if query.lower() == "exit":
            break

        answer = generate_answer(llm, retriever, vectorstore, query)
        print("\nAnswer:\n", answer)


if __name__ == "__main__":
    main()
